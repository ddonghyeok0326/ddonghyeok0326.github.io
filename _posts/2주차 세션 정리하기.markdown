---
layout: post
title:  "KHUDA 2주차 세션 정리"
date:   2024-07-28 21:39:46 +0900
categories: jekyll update
---
# Chapter 01

## 01-1

**인공지능**은 사람처럼 학습하고 추론할 수 있는 지능을 가진 컴퓨터 시스템을 만드는 기술
+ 인공일반지능(강인공지능) : 사람과 구분하기 어려운 지능을 가진 컴퓨터 시스템
    + 영화 속의 인공지능
+ 약인공지능 : 현실에서 우리가 마주하고 있는 인공지능
    + 자율 주행 자동차, 음악 추천, 알파고 ...


**머신러닝**은 규칙을 일일이 프로그래밍하지 않아도 자동으로 데이터에서 규칙을 학습하는 알고리즘을 연구하는 분야 (인공지능의 하위분야 중에서 지능을 구현하기 위한 소프트웨어를 담당하는 핵심분야)

※알고리즘 : 어떤 문제를 해결하기 위한 절차, 방법, 명령어들의 집합
+ 사이키럿 : 컴퓨터 과학 분야의 대표적인 머신러닝 라이브러리

**딥러닝**은 많은 머신러닝 알고리즘 중에 *인공 신경망*을 기반으로 한 방법들을 통칭
+ 인공 신경망이 발전한 원인
    + 복잡한 알고리즘을 훈련할 수 있는 풍부한 데이터
    + 컴퓨터 성능의 향상
    + 혁신적인 알고리즘 개발


## 01-2

**구글 코랩**은 웹 브라우저에서 무료로 파이썬 프로그램을 테스트하고 저장할 수 있는 서비스

코랩 노트북은 **구글 클라우드**의 가상 서버를 사용

**구글 드라이브**는 구글이 제공하는 클라우드 파일 저장 서비스로 코랩에서 만든 노트북은 **자동으로** 구글 클라우드의 'Colab NoteBooks'폴더에 저장

## 01-3

**도미와 빙어 구분하도록 머신러닝 하기(k-최근접 이웃 알고리즘 사용)**

+ step 1. 도미와 빙어 데이터 준비하기(http://bit.ly/bream_list, http://bit.ly/smelt_list)

+ step 2. 도미와 빙어 데이터 시각화하기(산점도 이용하기)
  + 필요한 라이브러리 가지고 오기
  ```python
  import matplotlib.pyplot as plt
  ```

  ```python
  plt.scatter(bream_length, bream_weight)
  plt.scatter(smelt_length, smelt_weight)
  plt.xlabel("length")
  plt.ylabel("weight")
  plt.show()
  ```
  ![01-03 산점도](https://github.com/user-attachments/assets/136c831f-3f37-4b5d-bd6f-9fc0b0c205f4)
    + scatter은 산점도를 나타낸다. bream_length, bream_weight로 x,y축 설정
    + x축과 y축의 이름을 나타낸다.

+ step 3. 머신러닝 할 수 있도록 데이터 세팅하기(리스트 인 리스트 형태)
  ```python
  lenght=bream_length + smelt_length #도미와 빙어의 길이 합쳐주기
  weight = bream_weight + smelt_weight

  #길이가 무게에 대응하도록 묶어주기
  fish_data = [[l,w] for l,w in zip(lenght, weight)]
  print(fish_data)

  #위에 저장되어 있는 데이터에서 정답알려주기(도미는 1 빙어는 0)
  fish_target = [1]*35 + [0] * 14
  print(fish_target)
  ```

+ step 4. k-최근접 이웃 알고리즘을 구현한 클래스인 KNeighborsClassifier를 import하기
  ```python
  from sklearn.neighbors import KNeighborsClassifier
  kn = KNeighborsClassifier() #객체 만들기
  ```
  + k-최근접 이웃 알고리즘은 어떤 데이터에 대한 답을 구할 때 주위의 다른 데이터를 보고 **다수**를 차지하는 것을 정답으로 사용
  + 기본적으로 5개의 데이터를 참고하지만 n_neighbors 매개변수를 바꾸어 참고하는 데이터 갯수를 바꿀 수 있다.
    ```python
    #ex
    kn49=KNeighborsClassifier(n_neighbors=49)
    ```

+ step 5. 도미를 찾기 위한 기준을 학습 및 모델을 평가하기
  ```python
  kn.fit(fish_data, fish_target) #input parameter로 학습시키기
  #처음 두 매개변수는 훈련에 사용할 특성과 정답 데이터
  kn.score(fish_data, fish_target) #평가하기
  #처음 두 매개션수로 특성과 정답 데이터를 전달
  ```
    + 직접 새로운 데이터를 예측할 수 있다
      ```python
      kn.predict([[30,600]]) #주변 데이터에서 도미가 많기 때문에 도미로 판단할 수 있다.
      #특성 데이터 하나만 매개변수로 전달
      ```
      ![스크린샷 2024-07-28 210814](https://github.com/user-attachments/assets/9ba00ff1-75da-4162-98ba-bfaa36b3ebbb)

**k-최근접 이웃 알고리즘**
+ 데이터를 모두 가지고 있게 하기(준비해야할 일)
+ 새로운 데이터를 예측할 경우 가장 가까운 직선거리에 어떤 데이터가 있는지 살피기
+ *단점*으로 데이터가 많은 경우 사용하기 힘듦