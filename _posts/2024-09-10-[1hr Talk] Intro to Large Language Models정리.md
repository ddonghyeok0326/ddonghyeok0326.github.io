---
layout: post
title:  "[1hr Talk] Intro to Large Language Models"
date:   2024-09-10 16:04:46 +0900
categories: jekyll update
---
# [1hr Talk] Intro to Large Language Models

## LLM Inference
### LLAMA2 72b model 
두 가지 큰 파일
+ 매개변수 파일
+ 매개변수를 실행하는 파일
+ 매개변수는 언어 모델을 구성하는 신경망의 가중치 또는 수치 값

GPU 클러스터를 사용하면 매우 큰 양의 인터넷 정보를 'zip 파일'과 비슷하게 압축해서 저장할 수 있음
+ 원래는 큰 양의 텍스트 데이터였던 것이 140GB의 매개 변수로 변환(대략 100배 압축)
+ 하지만 압축하는 과정에서 손실이 발생하기도 함 : '손실 있는 압축'은 원래 데이터와 동일한 결과물은 아님

학습한 텍스트에서 기본적인 패턴과 정보를 뽑아냈다고 볼 수 있음

## LMM Training
단어의 연속을 입력하고, 신경망 네트워크가 학습하면 어떤 관계들이 파악됌

네트워크 내에는 수많은 신경망들이 있고 서로 연결되어 작동

AI 학습 단계에는 'pre-training'과 'fine-tuning'이 있으며, pre-training은 인터넷에서 큰 양의 텍스트를 수집하고, fine-tuning은 수집한 해당 텍스트에서 적은 양의 대화형 문서집합으로 다시 학습하는 것이라고 함

+ pre-training : 많은 데이터를 수집할 수 있지만, 데이터의 품질이 괜찮은지 보장되지 않거나 데이터 중 실제 학습에 활용되지 않을 가능성이 높은 경우도 있음, 인터넷에서 많은 양의 텍스트 데이터를 수집하고 그것을 GPU 클러스터를 이용해 신경망 네트워크의 파라미터로 압축하여 베이스 모델을 구축
+ fine-tuning : 대화형 문서집합으로 다시 학습하여 데이터의 품질을 높이는 작업을 수행함, 학습에 사용되는 문서 집합의 양은 적지만 데이터 시각화가 잘 된 대화형 문서를 활용하여 학습을 진행, 텍스트를 라벨링하는 문서 작업이 필요하며 종종 Q&A단위로 수집, 베이스 모델을 구하면 파인튜닝 단계가 시작

AI 모델을 pre-training과 fine-tuning 단계로 나누어 공부
+ pre-training은 여러 인터넷 문서에서 지식을 얻고, fine-tuning은 그 문서의 양식을 질문-답변 자연스럽게 변환하는 일에 초점을 둠

사람들의 평가를 기반으로 모델을 개선하는 단계 3이 있는데, 이를 reinforcement learning from human feedback(RLHF)이라 부름

언어 모델의 발전으로 인해 인간-기계 협업을 통해 효율적이고 정확한 레이블을 생성할 수 있음

AI 모델의 개선을 위해 평가를 수행하고 배포하며 모니터링

잘못된 응답을 수정하기 위해 대화로 올바른 응답을 채우는 경과로, 훈련 데이터에 예시로서 삽입함

fine-tuning을 회사에서 많이 이용함(가격이 저렴하고 성능을 향상시킬 수 있기 때문임)

## LMM Dreams
모델은 훈련데이터에 따라 텍스트를 '몽상'하게 되며, 어떠한 믿을 수 있는 정보가 아닐 수 있음

따라서, 기계는 훈련데이터 분포를 따르는 형식으로 이상한 문장을 생성

인공신경망은 어떠한 훈련 세트를 보고 문서를 따라하기보다는, 손실이 가해지며 인터넷을 압축한 전반적인 지식을 기억하는 경향

네트워크가 보여주는 정답은 실제로는 틀린 답인지, 올바른 답인지 확실하게 알 수 없음
+ 대부분의 경우, 이것은 환각 혹은 인터넷 데이터에 기반한 몽상

인공신경망의 구조와 동작 방식은 세밀히 이해할 수는 없지만, 매개변수를 반복적으로 조절하여 다음 단어 예측 작업을 더 잘 수행하도록 네트워크를 최적화하는 방법은 알고 있음

## System1, System2
시스템1 사고
+ 빠르고 직감적이며 자동적
+ 대부분의 일을 처리

시스템2 사고
+ 천천히 의식적으로 복잡한 결정을 내리고 정착하는 것
+ 의식적이고 노력이 필요한 과정을 거침
+ 추론, 판단 과 같이 더 넓고 심화된 정보처리가 가능

대규모 언어 모델은 현재 추론력이나 판단력을 가진 시스템 2 를 갖고 있지 않음

시스템 2 가 있는 언어 모델은 추론, 판단 과 같이 더 넓고 심화된 정보처리가 가능

## LMM Security
JailBreak
+ llm을 속이려고 시도하면 쉽게 거짓말을 가르쳐주거나 거짓말 출력을 시킬 수 있음
+ llm은 다수의 파라미터를 가지는 인공신경망으로 구성된 컴퓨터 언어모델로, 방대한 텍스트를 사용하여 자기학습 또는 반자기학습에 의해 훈련되기 때문임

Prompt Injection
+ 대화형 언어 모델을 해킹하여 사용자로부터 새로운 지시를 받고, 이를 따르며 의도하지 않은 영향을 일으키는 것

Data poisoning
+ llm은 다양한 데이터를 학습하는데 잘못된 데이터로 학습될 경우 오해를 불러일으킴
