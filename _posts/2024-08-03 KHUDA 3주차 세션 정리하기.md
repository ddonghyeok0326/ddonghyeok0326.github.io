---
layout: post
title:  "KHUDA 2주차 세션 정리"
date:   2024-08-03 14:47:46 +0900
categories: jekyll update
---
# Chapter 03

## 03-01

### 들어가기



### 실습
+ step 1. 데이터 준비 및 산점도 그리기
    ```python
    #http://bit.ly/perch_data 이용
    import numpy as np
    import matplotlib.pyplot as plt
    plt.scatter(perch_length, perch_weight)
    plt.xlabel('length')
    plt.ylabel('weight')
    plt.show() #농어의 길이가 커짐에 따라 무게가 늘어남
    ```
+ step 2. 2차원 배열로 훈련 세트와 테스트 세트로 나누기
    ```python
    from sklearn.model_selection import train_test_split
    train_input, test_input, train_target, test_target = train_test_split(perch_length, perch_weight, random_state=42)

    #사이킷런에 사용할 훈련 세트는 2차원 배열이여야함(현재 1차원 배열)
    train_input = train_input.reshape(-1,1)
    test_input = test_input.reshape(-1,1)
    #행(row)의 위치에 -1을 넣고 열의 값을 지정(1로 지정함)해주면 변환될 배열의 행의 수는 알아서 지정이 된다는 뜻
    ```
    + reshape() 메서드는 쿠기가 바뀐 새로운 배열을 반환할 때 지정한 크기가 원본 배열에 있는 원소의 개수와 다르면 에러가 발생함

+ step 3.결정계수
    ```python
    from sklearn.neighbors import KNeighborsRegressor
    knr = KNeighborsRegressor()
    knr.fit(train_input, train_target)
    print(knr.score(test_input, test_target))
    ```
    + 회귀에서는 정확한 숫자를 맞힌다는 것은 거의 불가능함(예측하는 값이나 타깃 모두 임의의 수치라서)
    + 먼저 타깃과 예측한 값의 차이를 제곱 -> 타깃과 타깃 평균의 차이를 제곱한 값으로 나눔
    + 1에 가까울수록 정확도가 높음

    + 