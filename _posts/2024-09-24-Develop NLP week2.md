---
layout: post
title:  "Develop NLP week2"
date:   2024-09-24 21:59:46 +0900
categories: jekyll update
---
# 자연어처리(NLP) 기초

## 자연어처리란?

**자연어** : 우리가 일상 생활에서 사용하는 언어

**자연어 처리** : 자연어의 의미를 분석하여 컴퓨터가 처리할 수 있도록 하는 일

## NLP의 주요 구성 요소

1. **형태소 분석**
>+ *형태소*란 의미를 가지는 최소 단위
>+ 형태소를 분석하여 각 단어가 어떻게 구성되어 있는지 파악
>+ 예시) play(동사)ing(접미사)

2. **구문 분석**
>+ 문장 내 단어들의 관계와 구조를 분석하는 과정
>+ 주어-동사 사이의 관계, 문법 규칙을 확인
>+ *문장의 구조적 패턴을 분석*

3. **의미론**
>+ 문장이나 단어의 의미를 파악하는 단계
>+ 맥락에 따라서 달리 해석될 수 있음
>+ 예시) bank(강도, 은행)
>+ 문맥에 맞는 의미를 추출하는 것이 중요

4. **화용론**
>+ 문장이 사용되는 맥락에 따라 의미를 파악하는 과정
>+ 같은 문장이라도 상황이나 의도에 따라 다르게 해석될 수 있음
>+ 예시) 밥 뭐 먹었어(물음 or 답변)
>+ 이를 위해 대량의 데이터를 학습시켜야함

5. **담론 분석**
>+ *담론*이란 여러문장이 연결되어 특정한 의미를 전달하는 것
>+ 개별 문장보다 더 큰 단위인 담론을 분석하는 과정
>+ 연결 관계를 파악하여 전체적인 의미를 파악해야함

## 자연어처리와 딥러닝의 관계

자연어 처리는 앞으로 인공지능이 인간의 욕구와 행동을 이해하는 방식을 크게 바꿔 놓을 것이고 이를 위해 *딥러닝*이 핵심 역할

**딥러닝** : 신경망을 이용하여 데이터에서 직접적인 특징을 학습하는 것

**딥러닝 이전의 NLP**
>+ 주로 통계적 모델, 규칙 기반 시스템 사용
>+ 예시 ) 특정 규칙에 따라 단어 분석 -> n-그램 모델이나 HMM 같은 통계적 접근 방식이 주로 쓰임
>+ 성능이 제한적, 문맥을 제대로 이해하는 데 어려움

**딥러닝이 NLP에 미친 영향**

+ 딥러닝은 복잡한 패턴을 학습하는데 뛰어남
    >+ 자연어의 복잡한 구조와 문맥을 이해하는데 큰 도움이 됌

+ 주요 영향
>1. **특징 공학의 필요성 감소** : 전통적인 NLP모델은 사람의 개입 필요 -> 딥러닝은 데이터에서 직접 패턴을 학습 -> 사람이 일일이 특징을 추출할 필요 X
>2. **문맥 이해의 향상**

**딥러닝의 주요 모델과 기법**

1. 순환 신경망(RNN)
>+ 시퀀스 데이터를 처리하는데 적합한 모델로, NLP의 자연스러운 흐름을 처리
>+ RNN은 입력 시퀀스의 이전 상태를 메모리로 저장하고, 이를 바탕으로 다음 상태를 예측
>+ 긴 시퀀스 처리에서 *장기 의존성 문제*로 한계를 겪음
    >+ 장기 의존성 문제 : 입력과 출력 사이의 거리가 멀어질수록 연관 관계가 적어지는 문제

2. LSTM(Long Short-Term Memeory)
>+  LSTM은 RNN의 단점을 개선한 모델 -> 긴 시퀀스에서도 효과적으로 정보를 유지 가능
>+ NLP에서 자주 사용되는 모델이며 문장 내 긴 문맥 정보를 처리하는 데 탁월한 성능

3. Transformer 모델
+ 딥러닝 기반의 언어 모델 중에서도 가장 혁신적인 모델이며, *Attention Mechanism*을 사용하여 문맥을 효과적으로 처리
    + *Attention Mechanism*
        + Attention은 Transformer 모델의 핵심 개념
        + 문장의 각 단어에 가중치를 부여하여 중요한 단어나 문맥에 더 집중할 수 있게 함
        + 이를 통해 모델은 문맥을 더 잘 파악하고, 번역, 텍스트 생성 등 다양한 NLP 작업에서 더 나은 성능을 보일 수 있음


+ 기존의 RNN이나 LSTM과 달리 시퀀스를 순차적으로 처리하지 않고, **병렬**로 처리 -> 빠르고 효율적인 학습 가능
+ 긴 텍스트도 효율적으로 처리
+ BERT와 GPT 같은 언어 모델의 기반

**대표적인 딥러닝 기반 NLP 모델**
1. BERT(Bidirectional Encoder Representations from Transformers)
>+ 양방향 문맥을 이해하는데 특화(google AI에 의해 개발된 모델)
>+ 대량의 텍스트 데이터를 사전 학습한 후, 특정 작업(예 : 질문 응답)에 맞게 미세 조정되어 사용됨
>+ 문맥을 깊이 이해해야 하는 작업에 탁월

2. GPT
>+ 텍스트 생성 작업에 뛰어난 성능을 발휘하는 모델
>+ 주어진 텍스트 시퀀스를 기반으로 다음 단어를 예측하며, 매우 자연스러운 텍스트를 생성

## 자연어처리 활용 분야
+ 음성 인식
+ 내용 요약
+ 번역
+ 사용자의 감성 분석
+ 텍스트 분류 작업(스팸 메일 분류, 뉴스 기사 카테고리 분류)
+ 질의 응답 시스템, 챗봇과 같은 곳에서 사용되는 분야
+ <img width="219" alt="KakaoTalk_20240924_224206328" src="https://github.com/user-attachments/assets/765fc33e-731e-4106-9151-430f03efd738">

## NLP의 도전 과제
1. **다양한 언어 지원**
>+ 언어마다 문법, 단어의 형태, 어순 등이 다름 -> 오류 발생

2. **문맥 이해의 어려움**

3. **대량의 학습 데이터**
>+ 딥러닝 모델을 학습시키기 위해서는 대량의 텍스트 데이터가 필요함

# GPT같은 대규모 언어 모델의 원리와 활용

## Chat GPT란?
+ OpenAI가 개발한 GPT-3.5 기반의 대형 언어 모델(large language model, LLM) 챗봇
    + 대형 언어 모델 (large language model, LLM)은 일련의 단어에서 다음 단어를 예측하는 작업을 수행
+ 대화 형태로 상호작용을 하며 놀라울 정도로 인간과 대화하는 것과 같은 반응을 제공하는 능력을 가짐

+ 또한 ChatGPT는 인간 피드백형 강화학습 (Reinforcement Learning w/ Human Feedback, RLHF)을 사용 -> 이사용자의 지시를 따르고 만족스러운 반응을 생성하는 능력을 만들기 위해 인간 피드백을 사용하는 추가 훈련 계층

## GPT 만든사람 ?
+ ChatGPT는 샌프란시스코에 기반을 둔 인공지능 회사인 OpenAI에 의해 만들어짐
+ OpenAI는 DAL·E라는 텍스트 명령에서 이미지를 생성하는 딥 러닝 모델을 만든 회사로 유명함
+ Y Combinator의 사장이었던 Sam Altman이 현재 CEO로 재직중이며 마이크로소프트는 10억 달러 규모의 파트너이자 투자자
+ 그들은 또한 Azure AI 플랫폼을 공동으로 개발

## Chat GPT의 원리
스탠포드 대학에 따르면 GPT-3는 1,750억 개의 매개 변수를 가지고 있으며 570기가바이트의 텍스트에 대해 교육을 받음 (전작인 GPT-2는 15억 개의 매개변수에 100배 이상 해당되는 수치)

1. 대형 언어 모델(Large Language Model, LLM)
+ 문장에서 다음에 오는 단어를 정확하게 예측하기 위해 방대한 양의 데이터로 훈련됨
+ 데이터의 양을 늘리면 언어 모델의 수행 능력이 증가함
+ 문장의 일련의 단어로 다음 단어를 예측하고 다음 문장을 예측
    + 즉, 자동 완성과 유사하지만, 여러분을 사로잡는 정도로 예측
+ 이 기능을 통해 사용자들은 단락 뿐만 아니라 여러 페이지의 콘텐츠를 작성 가능

그러나 대형 언어 모델 (LLM)은 인간이 원하는 것을 항상 정확히 이해하지 못한다는 점에서 한계

2. 인간 피드백형 강화학습 (RLHF)

+ 이 한계점은 RLHF로 기술 수준이 개선 가능
+  이 훈련을 통해 ChatGPT는 사용자의 지시를 따르고 만족스러운 반응을 생성하는 능력을 만들 수 있음

## Chat GPT의 한계
1. **유독성 반응에 대한 한계**
+ ChatGPT는 유독하거나 유해한 반응을 제공하지 않도록 프로그램되어 있기 때문에 그러한 종류의 질문에 답변을 제공하지 못함
2. **입력의 품질에 의존하는 답변의 품질**
+ ChatGPT의 중요한 한계로, 출력 품질이 입력 품질에 의존 -> 전문가의 지시(프롬프트)가 더 나은 답을 만들어내는 셈
3. **부정확한 답변 제공**
+ 사용자가 옳다고 생각하는 답을 제공하도록 훈련되었기 때문에 제공한 답변이 사용자를 속일 수 있음
+ <img width="370" alt="KakaoTalk_20240924_225251159" src="https://github.com/user-attachments/assets/be45691e-4dca-4ac0-98e5-6945ee0520e1">
+ <img width="370" alt="KakaoTalk_20240924_225305967" src="https://github.com/user-attachments/assets/34241ffc-7400-4f88-a6f3-cb60990f378f">
+ <img width="240" alt="KakaoTalk_20240924_225621188" src="https://github.com/user-attachments/assets/51b0f6d3-7211-4992-be55-a327d64568bc">

## Chat GPT 활용사례(에세이 작성)
+ <img width="394" alt="KakaoTalk_20240924_225833779" src="https://github.com/user-attachments/assets/24732e52-1b1b-4f4b-a007-41c8bef03c91">
+ ‘마케팅 측면에서 AI 사용의 중요성’을 주제로 에세이 작성을 요청 -> 주장을 4가지로 나누며 마지막엔 결론까지 작성을 해내는 모습을 보임
+ 최근엔 ChatGPT를 통한 에세이 작성으로 대학교에서 A+ 성적을 낸 사례도 있음