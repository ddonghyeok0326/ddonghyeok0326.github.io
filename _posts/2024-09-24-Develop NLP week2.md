---
layout: post
title:  "Develop NLP week2"
date:   2024-09-24 21:59:46 +0900
categories: jekyll update
---
# 자연어처리(NLP) 기초

## 자연어처리란?

**자연어** : 우리가 일상 생활에서 사용하는 언어

**자연어 처리** : 자연어의 의미를 분석하여 컴퓨터가 처리할 수 있도록 하는 일

## NLP의 주요 구성 요소

1. **형태소 분석**
>+ *형태소*란 의미를 가지는 최소 단위
>+ 형태소를 분석하여 각 단어가 어떻게 구성되어 있는지 파악
>+ 예시) play(동사)ing(접미사)

2. **구문 분석**
>+ 문장 내 단어들의 관계와 구조를 분석하는 과정
>+ 주어-동사 사이의 관계, 문법 규칙을 확인
>+ *문장의 구조적 패턴을 분석*

3. **의미론**
>+ 문장이나 단어의 의미를 파악하는 단계
>+ 맥락에 따라서 달리 해석될 수 있음
>+ 예시) bank(강도, 은행)
>+ 문맥에 맞는 의미를 추출하는 것이 중요

4. **화용론**
>+ 문장이 사용되는 맥락에 따라 의미를 파악하는 과정
>+ 같은 문장이라도 상황이나 의도에 따라 다르게 해석될 수 있음
>+ 예시) 밥 뭐 먹었어(물음 or 답변)
>+ 이를 위해 대량의 데이터를 학습시켜야함

5. **담론 분석**
>+ *담론*이란 여러문장이 연결되어 특정한 의미를 전달하는 것
>+ 개별 문장보다 더 큰 단위인 담론을 분석하는 과정
>+ 연결 관계를 파악하여 전체적인 의미를 파악해야함

## 자연어처리와 딥러닝의 관계

자연어 처리는 앞으로 인공지능이 인간의 욕구와 행동을 이해하는 방식을 크게 바꿔 놓을 것이고 이를 위해 *딥러닝*이 핵심 역할

**딥러닝** : 신경망을 이용하여 데이터에서 직접적인 특징을 학습하는 것

**딥러닝 이전의 NLP**
+ 주로 통계적 모델, 규칙 기반 시스템 사용
+ 예시 ) 특정 규칙에 따라 단어 분석 -> n-그램 모델이나 HMM 같은 통계적 접근 방식이 주로 쓰임
+ 성능이 제한적, 문맥을 제대로 이해하는 데 어려움

**딥러닝이 NLP에 미친 영향**

+ 딥러닝은 복잡한 패턴을 학습하는데 뛰어남
    + 자연어의 복잡한 구조와 문맥을 이해하는데 큰 도움이 됌

+ 주요 영향
1. **특징 공학의 필요성 감소** : 전통적인 NLP모델은 사람의 개입 필요 -> 딥러닝은 데이터에서 직접 패턴을 학습 -> 사람이 일일이 특징을 추출할 필요 X

2. **문맥 이해의 향상**

**딥러닝의 주요 모델과 기법**

1. 순환 신경망(RNN)
+ 시퀀스 데이터를 처리하는데 적합한 모델로, NLP의 자연스러운 흐름을 처리
+ RNN은 입력 시퀀스의 이전 상태를 메모리로 저장하고, 이를 바탕으로 다음 상태를 예측
+ 긴 시퀀스 처리에서 *장기 의존성 문제*로 한계를 겪음
    + 장기 의존성 문제 : 입력과 출력 사이의 거리가 멀어질수록 연관 관계가 적어지는 문제

2. LSTM(Long Short-Term Memeory)
+  LSTM은 RNN의 단점을 개선한 모델 -> 긴 시퀀스에서도 효과적으로 정보를 유지 가능
+ NLP에서 자주 사용되는 모델이며 문장 내 긴 문맥 정보를 처리하는 데 탁월한 성능

3. Transformer 모델
+ 딥러닝 기반의 언어 모델 중에서도 가장 혁신적인 모델
+ 기존의 RNN이나 LSTM과 달리 시퀀스를 순차적으로 처리하지 않고, **병렬**로 처리 -> 빠르고 효율적인 학습 가능
+ BERT와 GPT 같은 언어 모델의 기반

**대표적인 딥러닝 기반 NLP 모델**
1. BERT(Bidirectional Encoder Representations from Transformers)
+ 양방향 문맥을 이해하는데 특화(google AI에 의해 개발된 모델)
+ 대량의 텍스트 데이터를 사전 학습한 후, 특정 작업(예 : 질문 응답)에 맞게 미세 조정되어 사용됨
+ 문맥을 깊이 이해해야 하는 작업에 탁월

2. GPT
+ 텍스트 생성 작업에 뛰어난 성능을 발휘하는 모델
+ 주어진 텍스트 시퀀스를 기반으로 다음 단어를 예측하며, 매우 자연스러운 텍스트를 생성

## 자연어처리 활용 분야
+ 음성 인식
+ 내용 요약
+ 번역
+ 사용자의 감성 분석
+ 텍스트 분류 작업(스팸 메일 분류, 뉴스 기사 카테고리 분류)
+ 질의 응답 시스템, 챗봇과 같은 곳에서 사용되는 분야
    + 
+ <img width="219" alt="KakaoTalk_20240924_224206328" src="https://github.com/user-attachments/assets/765fc33e-731e-4106-9151-430f03efd738">

## NLP의 도전 과제
1. **다양한 언어 지원**
>+ 언어마다 문법, 단어의 형태, 어순 등이 다름 -> 오류 발생

2. **문맥 이해의 어려움**

3. **대량의 학습 데이터**
>+ 딥러닝 모델을 학습시키기 위해서는 대량의 텍스트 데이터가 필요함

# GPT같은 대규모 언어 모델의 원리와 활용

## Chat GPT의 정의
+ OpenAI가 개발한 GPT-3.5 기반의 대형 언어 모델(large language model, LLM) 챗봇
+ 대화 형태로 상호작용을 하며 놀라울 정도로 인간과 대화하는 것과 같은 반응을 제공하는 능력을 가지고 있습니다.

대형 언어 모델 (large language model, LLM)은 일련의 단어에서 다음 단어를 예측하는 작업을 수행합니다.

또한 ChatGPT는 인간 피드백형 강화학습 (Reinforcement Learning w/ Human Feedback, RLHF)을 사용하는데요, 이는 사용자의 지시를 따르고 만족스러운 반응을 생성하는 능력을 만들기 위해 인간 피드백을 사용하는 추가 훈련 계층입니다.